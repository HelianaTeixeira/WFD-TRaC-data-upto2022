---
title: "R Notebook"
output:
  word_document: default
  html_notebook: default
---

Description: adapted to CW and TW from FW scripts by Geoff Phillips. 
Date: 11 April 2023. 
File name for script: BLM_boundaries_TraC_TP.Rmd

##  Background

This workbook shows an example of determining supporting element boundary values using a binary linear model, where the threshold probability used to calculate the boundary is identified using a confusion  matrix.  

To simplify the process a user function *modBLM* is used. This function runs the model, creates a series of confusion matrices and outputs possible boundary values.  Details of this are explained below.  The approach is 

1.  Setup, load libraries and functions
2.  Get the data
3.  Select the sub-set (e.g. type) to be modeled
4.  Run the model
5.  Generate figures to illustrate the results

The process from 3-5 can be repeated with results added to a data frame that can subsequently be used to tabulate results.

All of the functions used are in file *Function_BLM_EQR.R* which  needs to be loaded


##  Setup

First we load the libraries needed and run the user functions in R script *Functions_BLM_EQR.R*
```{r, include=TRUE}

#Load the required libraries (some of these may not be needed)
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(rms))
suppressPackageStartupMessages(library(modEvA))
suppressPackageStartupMessages(library(openxlsx)) 
suppressPackageStartupMessages(library(grid))# for multiple plot single legend
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(patchwork))#for grid layout of plots
#suppressPackageStartupMessages(library(lmtest))# for Breusch-Pagan Test for heteroscedascity
suppressPackageStartupMessages(library(ggpubr))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(knitr))

source("Functions_BLM_EQR.R")
```


##  Identify the SE to be modelled

The functions are intended to be sufficiently generic to allow any variable name to be used for the SE of interest

Add the name of the SE variable as in the data set used, for example *SecchiDepth_m*  

Add the text used for axis labels in plot functions  

Add the name of the binary dependent variable, the biological class (1 = Good, 0 =Not Good). The variable name *BinClass* can be generated in this script from the NEQR. However, if classification data are used, for example the WFD data sets then a different name can be used  

Set the number of decimals for rounding boundary values in plots

The first line of the following chunk lists the measures that are most useful and thus the ones included in table outputs.  (additional measures can  be specified, see *out$optEach$measure* for full list)


```{r, include=TRUE}
measure_used <- c("default","kappa","TKitMM","Com0.2","OmisComm","Com0.1","Sens0.9")# useful measures
SE <- "TP"    # name of data column containing SE in data file        
xlabel="Total Phosphorus (μg/L)"
BiotaClass <- "BinClass" # name of data column containing binary class
dec <- 2
```

##  Get the data

Load the data, and select the EQR variable used to establish the biota class.  The following chunk will need to be modified to match the data used.

The final data needs to include the 2 key variables
The concentration of the SE (variable name specified above in SE)
The binary class of the biota (default name is *BinClass*, but other variable names can be used)

In the example I get lake SoE data, filter for macrophyte records and use the variable *resultNormalisedEQRValue*  to convert to *BinClass*.  I also convert the EQR variable name to *NEQR* as this is used in my standard plot functions

```{r final results table}
# Create 2 data frames that can be used to hold the results from different subsets of the data
optEach_all <- data.frame()
BLMsum_all <- data.frame()
```


```{r getData, include=TRUE}
# Get the data
datIC <- read.csv(file = here("Databases","IC_selected_datasets.csv"),sep = ",") #EDIT file name / path

# Select the data for SE
datIC.TP <- datIC %>% 
  select (BQE,Country,WaterCategory,GIG,ICtype,Date_BQE,EQR,EQS,TP_µgL.1)%>% #EDIT: SE variable name
  filter(!is.na(TP_µgL.1)) %>% #EDIT: SE variable name
  #mutate(BinClass=ifelse(NEQR>=0.6,1,0)) #use this line instead when normalised EQR
  rename(TP=TP_µgL.1)%>%
  rename(BinClass=EQS)%>%
  rename(NEQR=EQR) #EDIT optional: but needs change also in functions be aware!, here kept NEQR even if not normalised in this IC dataset

```

##  Select subset of data and run the model

On the assumption that we want type specific boundary values I select this in the following chunk. I save this as a separate data object for convenience and as a record.
It is important to remove all SE missing values.


Then run the model function *modBLM*. This runs the model, generates a confusion matrix using the *modEva* package and collects useful outputs from the package.  Set plt=FALSE to suppress graphical output from  modEva (useful for additional information)

Output is returned as a list object to *out* which needs to be split into separate data frames

1.  *mod.pred*    the predicted values for the model used for plotting and to determine standard errors
2.  *allMeasures* data frame with values for each measure for probabilities 0-100. Used for  plotting  
3.  *optEach*  data frame with optimum value for each measure 

A series of functions are then used to add the confidence limits of the boundaries, the commission, omission and kappa values for each optimum threshold.  These are needed to select the most appropriate threshold probability.

Finally the function *IdentifyThreshold* is used to apply a proposed rule to identify the most appropriate threshold for any particular data set. The most appropriate threshold is identified by adding a variable *Select* to *optEach* setting this to 1.  This rule needs further discussion.  (note this function uses the variable df to split data sets.  It can thus be used to a dataframe containing the results from several model runs on different sub-sets of data)

The *out* object also contains the following Values which describe the quality of the model and the prevalence of the data used

*  out$Auc  the AUC for the model
*  out$psuedo.r2  the pseudo r^2^ of the model
*  out$Prev  the prevalence of the data set

Finally the results are added to summary data frames that I use to collect the results from several runs.  For example different types.

### TW type MED Polyhaline coastal lagoons 

```{r runModel}
#EDIT: Select the data subset
datIC.TP.MedPolyCL <- datIC.TP %>% 
  filter(ICtype %in% c("MEDTW")) %>% 
  filter(!is.na(.data[[SE]])) #remove missing values

#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datIC.TP.MedPolyCL

#EDIT: countries IC biota EQR G/M boundary when not using normalised NEQR
IC.GM_MS1 <- 0.39 # EDIT ID country: FR
IC.GM_MS2 <- 0.51 # EDIT ID country: IT
# add more MS if needed (in that case reflect in "Functions_BLM_EQR.R" to get all hlines in Fig1d)

#Run model and calculate measures
out <- modBLM(df=df,plt = FALSE, x=SE,y=BiotaClass,min_new.x=1,max_new.x=1,logarithm=TRUE)

# Split returned list into its constituent data frames
mod.pred <- out$mod.pred
allMeasures <- out$allMeasures

# Add additional variables
optEach <- out$optEach
optEach$lcl <- sapply(optEach$threshold,GetLCL)#lower confidence limit
optEach$ucl <- sapply(optEach$threshold,GetUCL)#upper confidence limit
optEach$commission <- sapply(optEach$threshold,GetCom)# commission value
optEach$omission <- sapply(optEach$threshold,GetOmi)# omission value
optEach$kappa <- sapply(optEach$threshold,GetKap)# kappa value
optEach$df <- out$df # name of data set used (for reference)
optEach <- optEach %>% filter(measure %in% measure_used) %>%  arrange(threshold)# filter measures and sort by ascending order of  p threshold

# run function to select the most appropriate threshold. Note in this script I include all the thresholds generated by modEva, plus the toolkit mis-match method.  This generates a longer list and it could be reduced by filtering the measures included in the optEach object that is passed to the function identifyThreshold()
optEach <- IdentifyThreshold()

#Collect the measures that are not threshold dependent.
BLMsum<- data.frame(out$df,out$pseudo.r2,out$Auc,out$Prev)
names(BLMsum) <- c("df","pseudo.r2","Auc","Prev")

# add the resulting model and boundary data to a summary file
optEach_all <- rbind(optEach_all,optEach)
BLMsum_all <- rbind(BLMsum_all,BLMsum)

# remove duplicate records, caused by running the chunk several times in error
optEach_all <- unique(optEach_all) 
BLMsum_all <- unique(BLMsum_all)
```

#### Inspect the results
scatterplot
```{r scatterplot SE vs BQE}
#EDIT: IC type SE boundaries
# IC.SE_GM_MS1lo <- 4.9
# IC.SE_GM_MS1up <- 6.5
# IC.SE_GM_MS2 <- 4

#scatterplot biota EQR vs SE
p0 <- GetScatterPLot0 (df=df,colName = SE,EQRVar="NEQR") 
p0 +
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
#EDIT below as needed according to countries' SE GM boundaries
  # + geom_vline(xintercept = IC.SE_GM_MS1lo,colour="#F8766D")+
  # geom_vline(xintercept = IC.SE_GM_MS1up,colour="#F8766D")+
  # geom_vline(xintercept = IC.SE_GM_MS2,colour="#00BFC4")+
  #   annotate(geom = "text",x=IC.SE_GM_MS1lo,y=0.1,label=IC.SE_GM_MS1lo,size=3,hjust=1,colour="#F8766D")+
  #   annotate(geom = "text",x=IC.SE_GM_MS1up,y=0.1,label=IC.SE_GM_MS1up,size=3,hjust=1,colour="#F8766D")+
  #   annotate(geom = "text",x=IC.SE_GM_MS2,y=0.1,label=IC.SE_GM_MS2,size=3,hjust=1,colour="#00BFC4")
```

density plot
```{r biota EQS vs SE density plot}
df$BinClass <- as.factor(df$BinClass)
p0d <- GetDensityPLot0 (df=df,colName = SE,EQSVar="BinClass")
p0d
```

####  All the results

Note that in the previous chunk I am not filtering out any of the measures.  For the work on rivers I only used max kappa, omission = commission, commission = 0.1, commission = 0.2.  I noticed that in the 2nd example below the automatic selection used the toolkit method as the optimum threshold. Not sure if this is appropriate or not.

The following figure shows the measures v probability.

```{r measures thresholds}
#list the points to mark on plot
meas <- c("CCR","kappa","TKitMM","Com0.2","OmisComm","Com0.1")# these are measures selected for lines on plot a:e
 pMeas()
```

The boundary values, thresholds etc are in object optEach.  The following table shows these,the most appropriate boundary, based on the criteria I am currently using are marked as Select = 1.

```{r threshold selection}
optEach  %>% select(Select,df,Bound,lcl,ucl,threshold,measure,value,commission,omission,kappa)
```

####  The boundary selected using current criteria

The most appropriate boundary is shown here

```{r boundary selected}
optEach %>% filter(Select==1) %>% select(df,Bound,lcl,ucl,threshold,measure,commission,omission,kappa)
```


The results can be illustrated using the following 4 figures.  Note that Figs 1b and 1d depend on the direction of the pressure response.  For most SEs a high value is indicative of increased pressure. For transparency a high value is less pressure, so I have defined this as a negative response and the negResp parameter in the function call needs to be set to TRUE.  For the logistic model plot the points may  be jittered. Set jith=0.01, although I am not certain it is needed.  Control the number of decimals with dec=


```{r plot 4 graphs}
#Plot will use output from the last model run, remember to re-run the model chunk if needed

#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datIC.TP.MedPolyCL #select data to plot

# select the boundary to be plotted i.e. the appropriate measure. 
meas_u <- optEach[optEach$Select==1,"measure"]  # use  measure selected by function
#meas_u <- "Com0.2"  #To plot a different measure use this line

tsize=2  #modify the size of text

p1 <- GetFig1a(df=df,meas=meas_u,colName = SE,EQRVar="NEQR",adj=0,dec=1,negResp = FALSE,jith=0)
p2 <- GetFig1b(df=df,meas=meas_u,colName = SE,negResp = FALSE) #EDIT: "TRUE" or "FALSE"
p3 <- GetFig1c(df=df,meas=meas_u,colName= SE)
p4 <- GetFig1d(df=df,meas=meas_u,EQRVar="NEQR",cat2=df$Country,colName= SE,negResp=FALSE)+ #EDIT cat2 as suitable for dataset
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.5,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.5,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
  
grid.arrange(p1,p2,p3,p4,ncol=2,nrow=2)

```

```{r scatterplot biota EQR vs SE predicted bound}
#scatterplot biota EQR vs SE
p5 <- GetScatterPLot(df=df,meas=meas_u,colName = SE,EQRVar="NEQR") 
p5 +
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
  
```



We can now repeat with another Type (change the name of the chunk if copying from above)

### CW types BC5 
To run on a different type, first select the data and then change the name of the data set when running the function (line with *modBLM* in chunk runModel#? below)

```{r runModel2}
#EDIT: Select the data subset
datIC.TP.BC5 <- datIC.TP %>% 
  filter(ICtype %in% c("BC5")) %>% #EDIT type
  filter(!is.na(.data[[SE]])) #remove missing values

#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datIC.TP.BC5

#EDIT: countries IC biota EQR G/M boundary when not using normalised NEQR
IC.GM_MS1 <- 0.39 # EDIT ID country: LV
IC.GM_MS2 <- 0.60 # EDIT ID country: LT
#add more MS if needed (in that case reflect in "Functions_BLM_EQR.R" to get all hlines in Fig1d)

#Run model and calculate measures
out <- modBLM(df=df,plt = FALSE, x=SE,y=BiotaClass,min_new.x=1,max_new.x=1,logarithm=TRUE)

# Split returned list into its constituent data frames
mod.pred <- out$mod.pred
allMeasures <- out$allMeasures

# Add additional variables
optEach <- out$optEach
optEach$lcl <- sapply(optEach$threshold,GetLCL)#lower confidence limit
optEach$ucl <- sapply(optEach$threshold,GetUCL)#upper confidence limit
optEach$commission <- sapply(optEach$threshold,GetCom)# commission value
optEach$omission <- sapply(optEach$threshold,GetOmi)# omission value
optEach$kappa <- sapply(optEach$threshold,GetKap)# kappa value
optEach$df <- out$df # name of data set used (for reference)
optEach <- optEach %>% filter(measure %in% measure_used) %>%  arrange(threshold)# filter measures and sort by ascending order of  p threshold

# run function to select the most appropriate threshold. Note in this script I include all the thresholds generated by modEva, plus the toolkit mis-match method.  This generates a longer list and it could be reduced by filtering the measures included in the optEach object that is passed to the function identifyThreshold()
optEach <- IdentifyThreshold()

#Collect the measures that are not threshold dependent.
BLMsum<- data.frame(out$df,out$pseudo.r2,out$Auc,out$Prev)
names(BLMsum) <- c("df","pseudo.r2","Auc","Prev")

# add the resulting model and boundary data to a summary file
optEach_all <- rbind(optEach_all,optEach)
BLMsum_all <- rbind(BLMsum_all,BLMsum)

# remove duplicate records, caused by running the chunk several times in error
optEach_all <- unique(optEach_all) 
BLMsum_all <- unique(BLMsum_all)

```

#### Inspect the results

scatterplot
```{r scatterplot SE vs BQE 2}
#scatterplot biota EQR vs SE
p6 <- GetScatterPLot0 (df=df,colName = SE,EQRVar="NEQR") 
p6 +
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```

density plot
```{r biota EQS vs SE density plot 2}
df$BinClass <- as.factor(df$BinClass)
p6d <- GetDensityPLot0 (df=df,colName = SE,EQSVar="BinClass")
p6d
```


####  The boundary selected using current criteria

```{r measures thresholds 2}
#list the points to mark on plot
meas <- c("CCR","kappa","TKitMM","Com0.2","OmisComm","Com0.1")
 pMeas()
```

```{r threshold selection 2}
optEach  %>% select(Select,df,Bound,lcl,ucl,threshold,measure,value,commission,omission,kappa)
```

```{r  boundary selected 2}
optEach %>% filter(Select==1) %>% select(df,Bound,lcl,ucl,threshold,measure,value,omission,commission,kappa)
```

```{r plot 4 graphs 2}
#Plot will use output from the last model run, remember to re-run the model chunk if needed
#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datIC.TP.BC5 #select data to plot

# select the boundary to be plotted i.e. the appropriate measure. 
meas_u <- optEach[optEach$Select==1,"measure"]  # use  measure selected by function
#meas_u <- "Com0.2"  #EDIT To plot a different measure use this line

tsize=2  #modify the size of text

p7 <- GetFig1a(df=df,meas=meas_u,colName = SE,EQRVar="NEQR",adj=0,dec=1,negResp = FALSE,jith=0)
p8 <- GetFig1b(df=df,meas=meas_u,colName = SE,negResp = FALSE) #EDIT: "TRUE" or "FALSE"
p9 <- GetFig1c(df=df,meas=meas_u,colName= SE)
p10 <- GetFig1d(df=df,meas=meas_u,EQRVar="NEQR",cat2=df$Country,colName= SE,negResp=FALSE)+#EDIT cat2 as suitable for dataset
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.5,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.5,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")

grid.arrange(p7,p8,p9,p10,ncol=2,nrow=2)
```

```{r scatterplot biota EQR vs SE predicted bound 2}
#scatterplot biota EQR vs SE
p11 <- GetScatterPLot(df=df,meas=meas_u,colName = SE,EQRVar="NEQR") 
p11+
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```



We can now repeat with another Type (change the name of the chunk if copying from above)

### CW types BC4 
To run on a different type, first select the data and then change the name of the data set when running the function (line with *modBLM* in chunk runModel#? below)

```{r Get data for BC4}
# Get the data
datBC4 <- read.csv(file = here("Databases","IC_BC4_NutTP-TN_Phyto.csv"),sep = ",") #EDIT file name / path

# Select the data for SE
datBC4.TP <- datBC4 %>% 
  select (Wcategory,GIG,Type,Country,Year,TP,CHLa,EQR_Chla,EQS)%>% #EDIT: SE variable name
  filter(!is.na(TP)) %>% #EDIT: SE variable name
  #mutate(BinClass=ifelse(NEQR>=0.6,1,0)) #use this line instead when normalised EQR
  mutate(BQE="Phytoplankton")%>%
  mutate(BinClass=case_when(EQS=="Moderate"|EQS=="Poor"|EQS=="Bad" ~ 0,
                            EQS=="High" | EQS == "Good" ~ 1)) %>%
  rename(NEQR=EQR_Chla) #EDIT optional: but needs change also in functions be aware!, here kept NEQR even if not normalised in this IC dataset

#TP is in µmol/l:
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.3400  0.6812  0.8028  0.8248  0.9425  1.5800 

#Convert TP concentrations to µg/l
# conversion: 1 µg P/l = 1/MW P = 0.032285 µmol/l

datBC4.TP<- datBC4.TP %>%
  mutate(TP=TP/0.032285)

#Checking conversion
 # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 #  10.53   21.10   24.87   25.55   29.19   48.94 

```


```{r runModel3}
#EDIT: Select the data subset
datBC4.TP <- datBC4.TP %>% 
  filter(!is.na(.data[[SE]])) #remove missing values

#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datBC4.TP

#EDIT: countries IC biota EQR G/M boundary when not using normalised NEQR
IC.GM_MS1 <- 0.67 # EDIT ID country: LV
IC.GM_MS2 <- 0.67 # EDIT ID country: LT
#add more MS if needed (in that case reflect in "Functions_BLM_EQR.R" to get all hlines in Fig1d)

#Run model and calculate measures
out <- modBLM(df=df,plt = FALSE, x=SE,y=BiotaClass,min_new.x=1,max_new.x=1,logarithm=TRUE)

# Split returned list into its constituent data frames
mod.pred <- out$mod.pred
allMeasures <- out$allMeasures

# Add additional variables
optEach <- out$optEach
optEach$lcl <- sapply(optEach$threshold,GetLCL)#lower confidence limit
optEach$ucl <- sapply(optEach$threshold,GetUCL)#upper confidence limit
optEach$commission <- sapply(optEach$threshold,GetCom)# commission value
optEach$omission <- sapply(optEach$threshold,GetOmi)# omission value
optEach$kappa <- sapply(optEach$threshold,GetKap)# kappa value
optEach$df <- out$df # name of data set used (for reference)
optEach <- optEach %>% filter(measure %in% measure_used) %>%  arrange(threshold)# filter measures and sort by ascending order of  p threshold

# run function to select the most appropriate threshold. Note in this script I include all the thresholds generated by modEva, plus the toolkit mis-match method.  This generates a longer list and it could be reduced by filtering the measures included in the optEach object that is passed to the function identifyThreshold()
optEach <- IdentifyThreshold()

#Collect the measures that are not threshold dependent.
BLMsum<- data.frame(out$df,out$pseudo.r2,out$Auc,out$Prev)
names(BLMsum) <- c("df","pseudo.r2","Auc","Prev")

# add the resulting model and boundary data to a summary file
optEach_all <- rbind(optEach_all,optEach)
BLMsum_all <- rbind(BLMsum_all,BLMsum)

# remove duplicate records, caused by running the chunk several times in error
optEach_all <- unique(optEach_all) 
BLMsum_all <- unique(BLMsum_all)

```

#### Inspect the results

scatterplot
```{r scatterplot SE vs BQE 3}
#scatterplot biota EQR vs SE
p12 <- GetScatterPLot0 (df=df,colName = SE,EQRVar="NEQR") 
p12 +
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```

density plot
```{r biota EQS vs SE density plot 3}
df$BinClass <- as.factor(df$BinClass)
p12d <- GetDensityPLot0 (df=df,colName = SE,EQSVar="BinClass")
p12d
```


####  The boundary selected using current criteria

```{r measures thresholds 3}
#list the points to mark on plot
meas <- c("CCR","kappa","TKitMM","Com0.2","OmisComm","Com0.1")
 pMeas()
```

```{r threshold selection 3}
optEach  %>% select(Select,df,Bound,lcl,ucl,threshold,measure,value,commission,omission,kappa)
```

```{r  boundary selected 3}
optEach %>% filter(Select==1) %>% select(df,Bound,lcl,ucl,threshold,measure,value,omission,commission,kappa)
```

```{r plot 4 graphs 3}
#Plot will use output from the last model run, remember to re-run the model chunk if needed
#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datBC4.TP #select data to plot

# select the boundary to be plotted i.e. the appropriate measure. 
meas_u <- optEach[optEach$Select==1,"measure"]  # use  measure selected by function
#meas_u <- "Com0.2"  #EDIT To plot a different measure use this line

tsize=2  #modify the size of text

p13 <- GetFig1a(df=df,meas=meas_u,colName = SE,EQRVar="NEQR",adj=0,dec=1,negResp = FALSE,jith=0)
p14 <- GetFig1b(df=df,meas=meas_u,colName = SE,negResp = FALSE) #EDIT: "TRUE" or "FALSE"
p15 <- GetFig1c(df=df,meas=meas_u,colName= SE)
p16 <- GetFig1d(df=df,meas=meas_u,EQRVar="NEQR",cat2=df$Country,colName= SE,negResp=FALSE)+#EDIT cat2 as suitable for dataset
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="black")+
  #geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.5,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.5,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")

grid.arrange(p13,p14,p15,p16,ncol=2,nrow=2)
```

```{r scatterplot biota EQR vs SE predicted bound 3}
#scatterplot biota EQR vs SE
p17 <- GetScatterPLot(df=df,meas=meas_u,colName = SE,EQRVar="NEQR") 
p17+
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="grey")+
  #geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```




We can now repeat with another Type (change the name of the chunk if copying from above)

### CW type TypeIIA Adriatic 

To run on a different type, first select the data and then change the name of the data set when running the function (line with *modBLM* in chunk runModel#? below)

```{r Get data for TypeIIA Adriatic}
# Get the data
datIIAAdriatic <- read.csv(file = here("Databases","IC_TypeIIAAdriatic_Nut_Phyto.csv"),sep = ",") #EDIT file name / path

# Select the data for SE
datIIAAdriatic.TP <- datIIAAdriatic %>% 
  select (Wcategory,GIG,Type,Country,Region,Date,Total_Phosphorus,Chla,EQR_Chla,EQS)%>% #EDIT: SE variable name
  filter(Region != "Abruzzo") %>% #drop samples from Abbruzzo following reported no trend (2018 report)
  filter(!is.na(Total_Phosphorus)) %>% #EDIT: SE variable name
  #mutate(BinClass=ifelse(NEQR>=0.6,1,0)) #use this line instead when normalised EQR
  rename(TP=Total_Phosphorus)%>%
  mutate(BQE="Phytoplankton")%>%
  mutate(BinClass=case_when(EQS=="not Good" ~ 0,
                            EQS=="High" | EQS == "Good" ~ 1)) %>%
  rename(NEQR=EQR_Chla) #EDIT optional: but needs change also in functions be aware!, here kept NEQR even if not normalised in this IC dataset

#TP is in µmol/l:
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  0.0300  0.2400  0.5490  0.7801  1.2335  6.3800 

#Convert TP concentrations to µg/l
# conversion: 1 µg P/l = 1/MW P = 0.032285 µmol/l

datIIAAdriatic.TP <- datIIAAdriatic.TP %>%
  mutate(TP=TP/0.032285)

#Checking conversion
 # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 #  0.9292   7.4338  17.0048  24.1635  38.2066 197.6150 

```


```{r runModel4}
#EDIT: Select the data subset
datIIAAdriatic.TP <- datIIAAdriatic.TP %>% 
  filter(!is.na(.data[[SE]])) #remove missing values

#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datIIAAdriatic.TP

#EDIT: countries IC biota EQR G/M boundary when not using normalised NEQR
IC.GM_MS1 <- 0.61 # EDIT ID country: IT
#IC.GM_MS2 <- 0.67 # EDIT ID country: LT
#add more MS if needed (in that case reflect in "Functions_BLM_EQR.R" to get all hlines in Fig1d)

#Run model and calculate measures
out <- modBLM(df=df,plt = FALSE, x=SE,y=BiotaClass,min_new.x=1,max_new.x=1,logarithm=TRUE)

# Split returned list into its constituent data frames
mod.pred <- out$mod.pred
allMeasures <- out$allMeasures

# Add additional variables
optEach <- out$optEach
optEach$lcl <- sapply(optEach$threshold,GetLCL)#lower confidence limit
optEach$ucl <- sapply(optEach$threshold,GetUCL)#upper confidence limit
optEach$commission <- sapply(optEach$threshold,GetCom)# commission value
optEach$omission <- sapply(optEach$threshold,GetOmi)# omission value
optEach$kappa <- sapply(optEach$threshold,GetKap)# kappa value
optEach$df <- out$df # name of data set used (for reference)
optEach <- optEach %>% filter(measure %in% measure_used) %>%  arrange(threshold)# filter measures and sort by ascending order of  p threshold

# run function to select the most appropriate threshold. Note in this script I include all the thresholds generated by modEva, plus the toolkit mis-match method.  This generates a longer list and it could be reduced by filtering the measures included in the optEach object that is passed to the function identifyThreshold()
optEach <- IdentifyThreshold()

#Collect the measures that are not threshold dependent.
BLMsum<- data.frame(out$df,out$pseudo.r2,out$Auc,out$Prev)
names(BLMsum) <- c("df","pseudo.r2","Auc","Prev")

# add the resulting model and boundary data to a summary file
optEach_all <- rbind(optEach_all,optEach)
BLMsum_all <- rbind(BLMsum_all,BLMsum)

# remove duplicate records, caused by running the chunk several times in error
optEach_all <- unique(optEach_all) 
BLMsum_all <- unique(BLMsum_all)

```

#### Inspect the results

scatterplot
```{r scatterplot SE vs BQE 4}
#scatterplot biota EQR vs SE
p12 <- GetScatterPLot0 (df=df,colName = SE,EQRVar="NEQR") 
p12 +
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="black")+
  #geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="black")
  #+annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```

density plot
```{r biota EQS vs SE density plot 4}
df$BinClass <- as.factor(df$BinClass)
p12d <- GetDensityPLot0 (df=df,colName = SE,EQSVar="BinClass")
p12d
```


####  The boundary selected using current criteria

```{r measures thresholds 4}
#list the points to mark on plot
meas <- c("CCR","kappa","TKitMM","Com0.2","OmisComm","Com0.1")
 pMeas()
```

```{r threshold selection 4}
optEach  %>% select(Select,df,Bound,lcl,ucl,threshold,measure,value,commission,omission,kappa)
```

```{r  boundary selected 4}
optEach %>% filter(Select==1) %>% select(df,Bound,lcl,ucl,threshold,measure,value,omission,commission,kappa)
```

```{r plot 4 graphs 4}
#Plot will use output from the last model run, remember to re-run the model chunk if needed
#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datIIAAdriatic.TP #select data to plot

# select the boundary to be plotted i.e. the appropriate measure. 
meas_u <- optEach[optEach$Select==1,"measure"]  # use  measure selected by function
#meas_u <- "Com0.2"  #EDIT To plot a different measure use this line

tsize=2  #modify the size of text

p13 <- GetFig1a(df=df,meas=meas_u,colName = SE,EQRVar="NEQR",adj=0,dec=1,negResp = FALSE,jith=0)
p14 <- GetFig1b(df=df,meas=meas_u,colName = SE,negResp = FALSE) #EDIT: "TRUE" or "FALSE"
p15 <- GetFig1c(df=df,meas=meas_u,colName= SE)
p16 <- GetFig1d(df=df,meas=meas_u,EQRVar="NEQR",cat2=df$Country,colName= SE,negResp=FALSE)+#EDIT cat2 as suitable for dataset
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="black")+
  #geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.5,label=IC.GM_MS1,size=3,vjust=1, colour="black")
  #annotate(geom = "text",y=IC.GM_MS2,x=0.5,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")

grid.arrange(p13,p14,p15,p16,ncol=2,nrow=2)
```

```{r scatterplot biota EQR vs SE predicted bound 4}
#scatterplot biota EQR vs SE
p17 <- GetScatterPLot(df=df,meas=meas_u,colName = SE,EQRVar="NEQR") 
p17+
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="grey")+
  #geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="black")
  #annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```


We can now repeat with another Type (change the name of the chunk if copying from above)

### TW types BT1 
To run on a different type, first select the data and then change the name of the data set when running the function (line with *modBLM* in chunk runModel#? below)
```{r get data BT1}
# Get the data
datBT1 <- read.csv(file = here("Databases","IC_BT1_NutTP-TN_Phyto.csv"),sep = ",") #EDIT file name / path

# Select the data for SE
datBT1.TP <- datBT1 %>% 
  select (Wcategory,GIG,Type,COUNTRY,Year,TP,CHLa,EQR,EQS)%>% #EDIT: SE variable name
  filter(!is.na(TP)) %>% #EDIT: SE variable name
  filter(!is.na(EQR)) %>% #EDIT: EQR variable name
  #mutate(BinClass=ifelse(NEQR>=0.6,1,0)) #use this line instead when normalised EQR
  rename(Country=COUNTRY)%>%
  mutate(BQE="Phytoplankton")%>%
  mutate(BinClass=case_when(EQS=="Bad" |EQS=="Moderate"|EQS =="Poor" ~ 0,
                            EQS=="High" | EQS == "Good" ~ 1)) %>%
  rename(NEQR=EQR) #EDIT optional: but needs change also in functions be aware!, here kept NEQR even if not normalised in this IC dataset

```


```{r runModel5}
#EDIT: Select the data subset
datBT1.TP <- datBT1.TP %>% 
  filter(!is.na(.data[[SE]])) #remove missing values

#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datBT1.TP

#EDIT: countries IC biota EQR G/M boundary when not using normalised NEQR
IC.GM_MS1 <- 0.57 # EDIT ID country: LT
IC.GM_MS2 <- 0.61 # EDIT ID country: PL
#add more MS if needed (in that case reflect in "Functions_BLM_EQR.R" to get all hlines in Fig1d)

#Run model and calculate measures
out <- modBLM(df=df,plt = FALSE, x=SE,y=BiotaClass,min_new.x=1,max_new.x=1,logarithm=TRUE)

# Split returned list into its constituent data frames
mod.pred <- out$mod.pred
allMeasures <- out$allMeasures

# Add additional variables
optEach <- out$optEach
optEach$lcl <- sapply(optEach$threshold,GetLCL)#lower confidence limit
optEach$ucl <- sapply(optEach$threshold,GetUCL)#upper confidence limit
optEach$commission <- sapply(optEach$threshold,GetCom)# commission value
optEach$omission <- sapply(optEach$threshold,GetOmi)# omission value
optEach$kappa <- sapply(optEach$threshold,GetKap)# kappa value
optEach$df <- out$df # name of data set used (for reference)
optEach <- optEach %>% filter(measure %in% measure_used) %>%  arrange(threshold)# filter measures and sort by ascending order of  p threshold

# run function to select the most appropriate threshold. Note in this script I include all the thresholds generated by modEva, plus the toolkit mis-match method.  This generates a longer list and it could be reduced by filtering the measures included in the optEach object that is passed to the function identifyThreshold()
optEach <- IdentifyThreshold()

#Collect the measures that are not threshold dependent.
BLMsum<- data.frame(out$df,out$pseudo.r2,out$Auc,out$Prev)
names(BLMsum) <- c("df","pseudo.r2","Auc","Prev")

# add the resulting model and boundary data to a summary file
optEach_all <- rbind(optEach_all,optEach)
BLMsum_all <- rbind(BLMsum_all,BLMsum)

# remove duplicate records, caused by running the chunk several times in error
optEach_all <- unique(optEach_all) 
BLMsum_all <- unique(BLMsum_all)

```

#### Inspect the results

scatterplot
```{r scatterplot SE vs BQE 5}
#scatterplot biota EQR vs SE
p18 <- GetScatterPLot0 (df=df,colName = SE,EQRVar="NEQR") 
p18 +
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```

density plot
```{r biota EQS vs SE density plot 5}
df$BinClass <- as.factor(df$BinClass)
p18d <- GetDensityPLot0 (df=df,colName = SE,EQSVar="BinClass")
p18d
```


####  The boundary selected using current criteria

```{r measures thresholds 5}
#list the points to mark on plot
meas <- c("CCR","kappa","TKitMM","Com0.2","OmisComm","Com0.1")
 pMeas()
```

```{r threshold selection 5}
optEach  %>% select(Select,df,Bound,lcl,ucl,threshold,measure,value,commission,omission,kappa)
```

```{r  boundary selected 5}
optEach %>% filter(Select==1) %>% select(df,Bound,lcl,ucl,threshold,measure,value,omission,commission,kappa)
```

```{r plot 4 graphs 5}
#Plot will use output from the last model run, remember to re-run the model chunk if needed
#EDIT: NEED TO MODIFY THE NEXT LINE to select appropriate data frame
df <- datBT1.TP #select data to plot

# select the boundary to be plotted i.e. the appropriate measure. 
meas_u <- optEach[optEach$Select==1,"measure"]  # use  measure selected by function
#meas_u <- "Com0.2"  #EDIT To plot a different measure use this line

tsize=2  #modify the size of text

p19 <- GetFig1a(df=df,meas=meas_u,colName = SE,EQRVar="NEQR",adj=0,dec=1,negResp = FALSE,jith=0)
p20 <- GetFig1b(df=df,meas=meas_u,colName = SE,negResp = FALSE) #EDIT: "TRUE" or "FALSE"
p21 <- GetFig1c(df=df,meas=meas_u,colName= SE)
p22 <- GetFig1d(df=df,meas=meas_u,EQRVar="NEQR",cat2=df$Country,colName= SE,negResp=FALSE)+#EDIT cat2 as suitable for dataset
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.5,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.5,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")

grid.arrange(p19,p20,p21,p22,ncol=2,nrow=2)
```

```{r scatterplot biota EQR vs SE predicted bound 5}
#scatterplot biota EQR vs SE
p23 <- GetScatterPLot(df=df,meas=meas_u,colName = SE,EQRVar="NEQR") 
p23+
  geom_hline(yintercept = IC.GM_MS1,lty=2, colour="#F8766D")+
  geom_hline(yintercept = IC.GM_MS2,lty=2, colour="#00BFC4")+
  annotate(geom = "text",y=IC.GM_MS1,x=0.1,label=IC.GM_MS1,size=3,vjust=1, colour="#F8766D")+
  annotate(geom = "text",y=IC.GM_MS2,x=0.1,label=IC.GM_MS2,size=3,vjust=0, colour="#00BFC4")
```









# other plots...
###  Plot without a fitted line
Examples showing the NEA11 data type

```{r}
# set z to any categorical variable name in the data set
pGLM_z(df=dat.IC.mac2.NEA,x=SE,z="ICtype") #EDIT z= "" as needed
```


###  Plot with fitted line
Examples showing the NEA11 data type

```{r}
# set z to any categorical variable name in the data set
pGLM_z_Alls(df=dat.IC.mac2.NEA,x=SE,z="ICtype") # function with #EDIT z= "" as needed
```



##  Table of combined results
To look at a set of combined results stored in optEach_all, first run the function to select the appropriate optima


```{r}
optEach_all <- IdentifyThreshold(optEach_all) # add the name of the summary data frame to the function call

optEach_all %>% filter(Select==1) %>% select(df,Select,Bound,lcl,ucl,threshold,measure,omission,commission,kappa)
```


